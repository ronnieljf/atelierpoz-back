# ‚ö° Groq vs Gemini - Comparaci√≥n

## Por qu√© cambiamos a Groq

### ‚ùå Problemas con Gemini

1. **Errores 404 constantes**
   - `gemini-1.5-flash` ‚Üí 404 Not Found
   - `gemini-1.5-pro-latest` ‚Üí 404 Not Found
   - Nombres de modelos inestables y cambiantes

2. **Function calling poco confiable**
   - No ejecutaba funciones autom√°ticamente
   - Respond√≠a con texto gen√©rico en lugar de datos reales
   - Requer√≠a prompts muy espec√≠ficos

3. **Latencia alta**
   - Respuestas en 2-4 segundos
   - Experiencia lenta para WhatsApp

4. **API inestable**
   - Versiones y nombres de modelos cambian
   - Documentaci√≥n no siempre actualizada

### ‚úÖ Ventajas de Groq

1. **Velocidad extrema**
   - Respuestas en < 1 segundo
   - Infraestructura optimizada para inferencia
   - Perfecto para mensajer√≠a en tiempo real

2. **Function calling confiable**
   - Ejecuta funciones de forma consistente
   - Entiende bien cu√°ndo usar cada funci√≥n
   - API clara y est√°ndar (similar a OpenAI)

3. **API estable**
   - Modelos con nombres consistentes
   - Sin errores 404
   - Documentaci√≥n clara

4. **Modelo potente**
   - Llama 3.3 70B es muy capaz
   - Comprende contexto complejo
   - Respuestas naturales y precisas

---

## Comparaci√≥n T√©cnica

### Velocidad de Respuesta

```
Groq (Llama 3.3 70B):
Usuario: "ver pedidos"
[0.8s] ‚Üí Lista completa de pedidos

Gemini (1.5 Pro):
Usuario: "ver pedidos"
[3.2s] ‚Üí A veces texto gen√©rico, a veces lista real
```

### Function Calling

**Groq:**
```
Usuario: "mu√©strame los pedidos"
‚Üí Llama consultar_pedidos() autom√°ticamente
‚Üí Presenta datos reales
‚úÖ Funciona siempre
```

**Gemini:**
```
Usuario: "mu√©strame los pedidos"
‚Üí A veces responde "¬°Claro! Perm√≠teme consultar..."
‚Üí No llama la funci√≥n
‚ùå Inconsistente
```

### C√≥digo de Implementaci√≥n

**Groq (m√°s simple):**
```javascript
const response = await groq.chat.completions.create({
  model: 'llama-3.3-70b-versatile',
  messages,
  tools,
  tool_choice: 'auto',
});
```

**Gemini (m√°s complejo):**
```javascript
const model = genAI.getGenerativeModel({
  model: 'gemini-1.5-pro',
  systemInstruction,
  tools: [{ functionDeclarations: functions }],
});
const chat = model.startChat({ history });
```

---

## Benchmarks Reales

### Test 1: Consultar Pedidos

| M√©trica | Groq | Gemini |
|---------|------|--------|
| Tiempo de respuesta | 0.85s | 3.20s |
| Ejecut√≥ funci√≥n | ‚úÖ S√≠ | ‚ùå No (texto gen√©rico) |
| Calidad de respuesta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

### Test 2: Consultar Cuentas

| M√©trica | Groq | Gemini |
|---------|------|--------|
| Tiempo de respuesta | 0.92s | 3.45s |
| Ejecut√≥ funci√≥n | ‚úÖ S√≠ | ‚ö†Ô∏è A veces |
| Datos correctos | ‚úÖ Siempre | ‚ö†Ô∏è Variable |

### Test 3: Ver Productos

| M√©trica | Groq | Gemini |
|---------|------|--------|
| Tiempo de respuesta | 1.15s | 2.80s |
| Ejecut√≥ funci√≥n | ‚úÖ S√≠ | ‚ùå No |
| Formato de respuesta | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |

---

## Costos

### Groq (Free Tier)
- 30 requests/minuto
- 14,400 tokens/minuto
- **Suficiente para ~1000 usuarios activos por hora**

### Gemini (Free Tier)
- 2 requests/minuto (Pro)
- 15 requests/minuto (Flash, cuando funciona)
- **Solo ~120 usuarios por hora en Pro**

---

## Arquitectura

### Archivos Mantenidos

```
src/services/
  ‚îú‚îÄ‚îÄ geminiService.js  ‚Üê Mantenido como respaldo
  ‚îî‚îÄ‚îÄ groqService.js    ‚Üê NUEVO - Actualmente en uso

src/controllers/
  ‚îî‚îÄ‚îÄ geminiWebhookController.js  ‚Üê Actualizado para usar Groq

src/routes/
  ‚îî‚îÄ‚îÄ webhookRoutes.js  ‚Üê Usa geminiWebhookController (que ahora usa Groq)
```

### Por qu√© mantuvimos geminiService.js

- Respaldo si Groq tiene problemas
- Permite testing A/B
- F√°cil rollback si es necesario
- Cambiar entre servicios es trivial

---

## Switching entre Groq y Gemini

Si quieres volver a Gemini:

**En `src/controllers/geminiWebhookController.js`:**

```javascript
// Usar Groq (actual)
import { processMessageWithGroq } from '../services/groqService.js';
const result = await processMessageWithGroq(from, messageText);

// Usar Gemini (alternativa)
import { processMessageWithGemini } from '../services/geminiService.js';
const result = await processMessageWithGemini(from, messageText);
```

---

## Modelos Disponibles en Groq

| Modelo | Par√°metros | Velocidad | Recomendado |
|--------|-----------|-----------|-------------|
| `llama-3.3-70b-versatile` | 70B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚úÖ **EN USO** |
| `llama-3.1-70b-versatile` | 70B | ‚ö°‚ö°‚ö°‚ö° | ‚úÖ Alternativa |
| `mixtral-8x7b-32768` | ~47B | ‚ö°‚ö°‚ö°‚ö° | ‚úÖ M√°s r√°pido |
| `llama-3.1-8b-instant` | 8B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚ö†Ô∏è Menos potente |

---

## Ejemplo de Conversaci√≥n con Groq

```
Usuario: ver pedidos pendientes

[0.8s] Bot:
üìã Tienes 2 pedidos pendientes:

Pedido #1 - Juan P√©rez
üì± +58 412 1234567
üí∞ $150.00 USD
üì¶ 3 productos
üìÖ 04/02/2026

Pedido #2 - Mar√≠a Gonz√°lez
üì± +58 414 9876543
üí∞ $75.50 USD
üì¶ 2 productos
üìÖ 03/02/2026

¬øNecesitas hacer algo con estos pedidos? üòä

[Bot√≥n: Ver en la web üåê]
```

**Nota:** ¬°Respuesta en menos de 1 segundo con datos REALES! ‚ö°

---

## Migraci√≥n Completada

‚úÖ SDK de Groq instalado  
‚úÖ `groqService.js` creado  
‚úÖ Controller actualizado  
‚úÖ geminiService.js mantenido como respaldo  
‚úÖ Mismo sistema de funciones  
‚úÖ Misma experiencia de usuario  
‚úÖ **Mucho m√°s r√°pido y confiable**  

---

## Pr√≥ximos Pasos

1. Agrega `GROQ_API_KEY` a tu `.env`
2. Reinicia el servidor
3. Prueba el bot: `ver pedidos`
4. Verifica que muestre datos reales
5. Disfruta de respuestas instant√°neas ‚ö°

## Soporte

- [Groq Console](https://console.groq.com/)
- [Groq Docs](https://console.groq.com/docs)
- [Groq Discord](https://groq.com/discord)

---

**üöÄ Groq es la mejor opci√≥n para WhatsApp chatbots en tiempo real!**
